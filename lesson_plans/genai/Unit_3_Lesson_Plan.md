Here's a detailed lesson plan for Learning Unit 3: Natural Language Processing and Word Embeddings, formatted in Markdown:

# Lesson Plan: Natural Language Processing and Word Embeddings

## 1. Resources Needed

- Computers with internet access for each student or pair of students
- Projector for demonstrations
- Access to a pre-trained word embedding model (e.g., Word2Vec or GloVe)
- Jupyter Notebooks prepared with code examples
- Handouts with key NLP concepts and vocabulary

## 2. Lesson Objectives

By the end of this lesson, students will be able to:
- Define natural language processing and its key components
- Explain the concept of word embeddings and their importance in NLP
- Use a pre-trained word embedding model to explore word relationships
- Discuss potential applications of NLP in Tetum and Portuguese languages

## 3. Warm-up Activity (10 minutes)

- Word association game: Students pair up and take turns saying a word. Their partner must quickly respond with the first related word that comes to mind.
- Class discussion: How might a computer understand and generate these word associations?

## 4. Pre-teaching Key Vocabulary (15 minutes)

Introduce and explain the following terms:
- Natural Language Processing (NLP)
- Tokenization
- Part-of-speech tagging
- Named Entity Recognition (NER)
- Word embedding
- Vector space
- Semantic similarity

## 5. Presentation of Main Lesson Content (30 minutes)

### Introduction to NLP
- Definition and importance of NLP
- Key tasks in NLP: tokenization, POS tagging, NER, etc.
- Challenges in processing natural language

### Word Embeddings
- Concept of representing words as vectors
- Advantages of word embeddings over traditional representations
- Introduction to Word2Vec and its underlying principles

### Applications in Tetum and Portuguese
- Discuss challenges and opportunities for NLP in these languages
- Examples of existing NLP applications in similar low-resource languages

## 6. Practice Activities (30 minutes)

- Guided Jupyter Notebook exercise:
  * Load a pre-trained word embedding model
  * Explore word similarities and analogies
  * Visualize word relationships in vector space

## 7. Production Tasks (30 minutes)

- Group brainstorming session:
  * Students form small groups to discuss potential NLP applications for preserving Timorese languages and culture
  * Each group presents their top idea to the class

## 8. Wrap-up and Review (15 minutes)

- Quick quiz on key concepts covered in the lesson
- Open discussion: What surprised you most about word embeddings and NLP?

## 9. Homework Assignment

- Research and write a short report (500 words) on an existing NLP application in a Southeast Asian language
- Experiment with the word embedding model used in class, finding interesting word relationships in English (or Tetum/Portuguese if available)

## 10. Key Vocabulary Definitions

- Natural Language Processing (NLP): A field of AI focused on the interaction between computers and human language
- Tokenization: The process of breaking down text into individual words or subwords
- Part-of-speech tagging: Assigning grammatical categories (e.g., noun, verb) to words in a text
- Named Entity Recognition (NER): Identifying and classifying named entities (e.g., person names, locations) in text
- Word embedding: A learned representation for text where words with similar meanings have similar representations
- Vector space: A mathematical space where word embeddings are represented as vectors
- Semantic similarity: The degree of relatedness between words or phrases based on their meaning